{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Linear and Regularized Regression Models on Synthetic Data\n\nThis script demonstrates the use of linear regression models and their regularized counterparts (Ridge, \nLASSO, and ElasticNet) on synthetic data. The models are fitted to 1D and 2D datasets, and performance \nis evaluated through residual analysis, summary statistics, and visualizations.\n\nThe following models are used:\n- Linear Regression\n- Ridge Regression\n- LASSO Regression\n- ElasticNet Regression\n\nThis script also explores the effect of sample weighting on model training, with particular focus on \nLASSO and ElasticNet regressions, and tracks training metrics such as loss and RMSE during optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport scienceplots\n\nfrom DLL.MachineLearning.SupervisedLearning.LinearModels import LinearRegression, RidgeRegression, LASSORegression, ElasticNetRegression\nfrom DLL.Data.Metrics import r2_score, adjusted_r2_score\nfrom DLL.DeepLearning.Optimisers import LBFGS, ADAM\n\n\nplt.style.use([\"grid\", \"notebook\"])\n\ndef summary(predictions, true_values, n_features):\n    print(\"======================== SUMMARY ========================\")\n    residuals = true_values - predictions\n    residual_quantiles = torch.min(residuals).item(), torch.quantile(residuals, 0.25).item(), torch.quantile(residuals, 0.50).item(), torch.quantile(residuals, 0.75).item(), torch.max(residuals).item()\n    print(f\"Residual quantiles: {tuple(round(item, 3) for item in residual_quantiles)}\")\n    r_squared = r2_score(predictions, true_values)\n    print(f\"Coefficient of determination: {round(r_squared, 3)}\")\n    adjusted_r_squared = adjusted_r2_score(predictions, true_values, n_features)\n    print(f\"Adjusted R squared: {round(adjusted_r_squared, 3)}\")\n\ndef plot_residuals(predictions, true_values):\n    fig, ax = plt.subplots(1, 2, figsize=(14,7))\n    residuals = true_values - predictions\n    ax[0].plot(residuals, \".\")\n    ax[0].axhline(y=torch.mean(residuals))\n    stats.probplot(residuals, dist=\"norm\", plot=ax[1])\n    ax[0].set_title('Residuals Plot')\n    ax[0].set_xlabel('Index')\n    ax[0].set_ylabel('Residuals')\n    ax[1].set_title('Q-Q Plot')\n\ndef plot1d(x, true_values, predictions, title):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.plot(x, true_values, \".\", color=\"red\", label=\"true values\")\n    ax.plot(x, predictions, color=\"blue\", label=\"predictions\")\n    ax.legend()\n    ax.set_title(title)\n\ndef plot2d(model, X, true_values, title):\n    x = X[:, 0]\n    y = X[:, 1]\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(x, y, true_values, label=\"true values\", color=\"red\")\n    x = torch.linspace(torch.min(x), torch.max(x), 2)\n    y = torch.linspace(torch.min(y), torch.max(y), 2)\n    XX, YY = torch.meshgrid(x, y, indexing=\"xy\")\n    X = XX.flatten()\n    Y = YY.flatten()\n    X_input = torch.stack((X, Y), dim=1)\n    ax.plot_surface(XX, YY, model.predict(X_input).reshape(XX.size()), color=\"blue\", alpha=0.5, label=\"predictions\")\n    ax.legend()\n    ax.set_title(title)\n\n\nx = torch.linspace(0, 1, 20)\ny = torch.linspace(0, 1, 20)\nXX, YY = torch.meshgrid(x, y, indexing=\"xy\")\nX = XX.flatten()\nY = YY.flatten()\nX_input = torch.stack((X, Y), dim=1)\nZ = 2 * X - 5 * Y + torch.normal(0, 1, size=X.size())\n\nmodel1 = LinearRegression()\nmodel2 = RidgeRegression(alpha=1.0)\nmodel3 = LASSORegression(alpha=1.0)\nmodel4 = ElasticNetRegression(alpha=1.0, l1_ratio=0.5)\nmodel1.fit(X_input, Z, method=\"tls\")\nsummary(model1.predict(X_input), Z, X_input.shape[1])\nplot2d(model1, X_input, Z, \"Linear regression\")\nplot_residuals(model1.predict(X_input), Z)\nmodel2.fit(X_input, Z)\nsummary(model2.predict(X_input), Z, X_input.shape[1])\nplot2d(model2, X_input, Z, \"Ridge regression\")\nmodel3.fit(X_input, Z, epochs=100)\nsummary(model3.predict(X_input), Z, X_input.shape[1])\nplot2d(model3, X_input, Z, \"LASSO regression\")\nmodel4.fit(X_input, Z, epochs=100)\nsummary(model4.predict(X_input), Z, X_input.shape[1])\nplot2d(model4, X_input, Z, \"Elasticnet regression\")\nplt.show()\n\nX = torch.linspace(0, 1, 100).unsqueeze(dim=1)\nweight = torch.zeros_like(X.squeeze())\nweight[:50] = 1\n# weight = None\ny = 2 * X.squeeze() + torch.normal(0, 0.1, size=(100,))\ny[:50] = (-2 * X.squeeze() + torch.normal(0, 0.1, size=(100,)))[:50]\n\nmodel1.fit(X, y, sample_weight=weight, method=\"ols\")\nsummary(model1.predict(X), 2 * X.squeeze(), 1)\nplot1d(X, y, model1.predict(X), \"Linear regression\")\nmodel2.fit(X, y, sample_weight=weight)\nsummary(model2.predict(X), 2 * X.squeeze(), 1)\nplot1d(X, y, model2.predict(X), \"Ridge regression\")\nhistory_lasso = model3.fit(X, y, sample_weight=weight, epochs=100, metrics=[\"loss\", \"rmse\"])\nsummary(model3.predict(X), 2 * X.squeeze(), 1)\nplot1d(X, y, model3.predict(X), \"LASSO regression\")\nhistory_elasticnet = model4.fit(X, y, sample_weight=weight, epochs=100, metrics=[\"loss\", \"rmse\"])\nsummary(model4.predict(X), 2 * X.squeeze(), 1)\nplot1d(X, y, model4.predict(X), \"Elasticnet regression with all weight on first 50 samples\")\n\nfig, ax = plt.subplots(1, 2)\nax[0].plot(history_elasticnet[\"rmse\"], label=\"rmse\")\nax[1].plot(history_elasticnet[\"loss\"], label=\"loss\")\nfig.suptitle(\"Elasticnet regresson\")\nax[0].set_xlabel(\"epoch\")\nax[0].set_ylabel(\"rmse\")\nax[1].set_xlabel(\"epoch\")\nax[1].set_ylabel(\"loss\")\nax[0].legend()\nax[1].legend()\n\nfig, ax = plt.subplots(1, 2)\nax[0].plot(history_lasso[\"rmse\"], label=\"rmse\")\nax[1].plot(history_lasso[\"loss\"], label=\"loss\")\nfig.suptitle(\"LASSO regresson\")\nax[0].set_xlabel(\"epoch\")\nax[0].set_ylabel(\"rmse\")\nax[1].set_xlabel(\"epoch\")\nax[1].set_ylabel(\"loss\")\nax[0].legend()\nax[1].legend()\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}